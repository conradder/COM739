{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "COM739_17952_CW3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4M-Qf6JZWuD"
      },
      "source": [
        "**Initial Setup**\n",
        "\n",
        "1. First, you will setup your CoLab environment. Run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyDn8qrkcDRx"
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLuQyFfv945l"
      },
      "source": [
        "Now we authenticate a Google Drive client to download the file we will be processing in our Spark job.\n",
        "\n",
        "**Make sure to follow the interactive instructions.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq_Z4KZBlz1Y"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzgVstB--CBc"
      },
      "source": [
        "Download both anime.csv and rating.csv, and store it in your google drive. It is advisable to create a separate project folder, where you can store this dataset and also your code.\n",
        "\n",
        "The script will give you the id of the two files in your drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTCTGdj90mvn"
      },
      "source": [
        "file_list = drive.ListFile({'q': \"'1Oi8cMnAfJVZH9-FyXGxwOrGGCIkkB7uy' in parents\"}).GetList()\n",
        "for f in file_list:\n",
        "  print('title: %s, id: %s' % (f['title'], f['id']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zwibooR_do9"
      },
      "source": [
        "If you executed the cells below, you should be able to see the dataset we will need for this Colab under the \"Files\" tab on the left panel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDb3bcspuvyi"
      },
      "source": [
        "# Change the id, if it differs from the one below.\n",
        "id='1TppJoj4QVJlc_HML20xmH847Brrw0Zfc'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('anime.csv')\n",
        "\n",
        "id='1f76dQZxRB1fNaReBv_DnUDVkIXNm7mw9'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('rating.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkVgWJCZ_kA1"
      },
      "source": [
        "Here is a list of packages that might be useful to you. \n",
        "\n",
        "**Student Activity: Add the packages you need to carry out your analysis here** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6S53q8Ur9cf"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Student Activity: Add your packages here.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLvokhSvcMcG"
      },
      "source": [
        "**This step initializes the Spark context.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQXrcZwKZOhO"
      },
      "source": [
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJmuKtJUagDZ"
      },
      "source": [
        "You can easily check the current version and get the link of the web interface. In the Spark UI, you can monitor the progress of your job and debug the performance bottlenecks (if your Colab is running with a local runtime)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT25Rxufje4A"
      },
      "source": [
        "spark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK9ISlEuAnkM"
      },
      "source": [
        "## **From this point onwards, you are supposed to do the coding yourself. Follow the steps as mentioned below in its appropriate place.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r6S-Jr4A52U"
      },
      "source": [
        "**1. Student Activity: Read the datasets here. You must write the script for the first question and explore both the files here.**\n",
        "\n",
        "Q1. Identify and describe the number of columns in the two dataset files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce0qaZfDhsdo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm7N9uNYbs_y"
      },
      "source": [
        "**2. Student Activity: Preprocess the datasets here. You must write the script for the second question here. Make sure to check if the script is running is correctly or not**\n",
        "\n",
        "Q2. Merge/Join/Combine the two datasets and identify the key common column that would you have performed? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWQ4NGpl9btl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwtkcRCYCemO"
      },
      "source": [
        "**3. Student Activity: Now do some exploratory analysis. You must write the script for the third and fourth question here. Make sure to check if the script is running is correctly or not**\n",
        "\n",
        "Q3. Find the top 10 anime based on rating. Use tabular/graphical presentation to provide evidence of your analysis.\n",
        "\n",
        "Q4. Find the top 10 anime with the most episodes. Use tabular/graphical presentation to provide evidence of your analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zADjKUlIKCp3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFSH_STSEUcd"
      },
      "source": [
        "**4. Student Activity: Design the recommendation system. Remember to split the dataset into training and testing to validate your recommendation model. This section would help you in answering question 5**\n",
        "\n",
        "Q5. Design a collaborative filter-based recommendation system. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH0S0cGHsdz6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe1VOcREEzQW"
      },
      "source": [
        "**Student Activity: Analyse the output of the test dataset here.**\n",
        "\n",
        "Q6. Give example of best three anime recommendations for minimum of 10 users."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdob4pMiWbaQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}